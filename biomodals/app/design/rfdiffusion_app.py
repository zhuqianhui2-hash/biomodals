"""
RFdiffusion on Modal - minimal runnable scaffold (fixed).

Typical usage:

  # 1) download models into the Modal Volume (run once)
  modal run rfdiffusion_app.py --download-models --force-redownload

  # 2) run inference (binder design / scaffold etc.)
  modal run rfdiffusion_app.py \
    --run-name test1 \
    --input-pdb ~/outputs/RFdiffusion/RBD_wt.pdb \
    --rfd-args "contigmap.contigs='[100-150/0 E333-526]' inference.num_designs=2 ppi.hotspot_res=[E405,E408]"
"""

import os
import shlex
from pathlib import Path

from modal import App, Image, Volume


# -------------------------
# Modal configs
# -------------------------
GPU = os.environ.get("GPU", "A100")
TIMEOUT = int(os.environ.get("TIMEOUT", "36000"))
APP_NAME = os.environ.get("MODAL_APP", "RFdiffusion")

RFD_VOLUME = Volume.from_name("rfdiffusion-models", create_if_missing=True)
RFD_OUT_VOLUME = Volume.from_name("rfdiffusion-outputs", create_if_missing=True)

RFD_REPO_DIR = "/root/RFdiffusion"
RFD_MODELS_DIR = f"{RFD_REPO_DIR}/models"
RFD_OUT_DIR = "/root/rfdiffusion_outputs"

# -------------------------
# RFdiffusion checkpoints (hardcoded from upstream download_models.sh)
# https://github.com/RosettaCommons/RFdiffusion/blob/main/scripts/download_models.sh
# -------------------------
RFD_CHECKPOINT_URLS: dict[str, str] = {
    "Base_ckpt.pt": "http://files.ipd.uw.edu/pub/RFdiffusion/6f5902ac237024bdd0c176cb93063dc4/Base_ckpt.pt",
    "Complex_base_ckpt.pt": "http://files.ipd.uw.edu/pub/RFdiffusion/e29311f6f1bf1af907f9ef9f44b8328b/Complex_base_ckpt.pt",
    "Complex_Fold_base_ckpt.pt": "http://files.ipd.uw.edu/pub/RFdiffusion/60f09a193fb5e5ccdc4980417708dbab/Complex_Fold_base_ckpt.pt",
    "InpaintSeq_ckpt.pt": "http://files.ipd.uw.edu/pub/RFdiffusion/74f51cfb8b440f50d70878e05361d8f0/InpaintSeq_ckpt.pt",
    "InpaintSeq_Fold_ckpt.pt": "http://files.ipd.uw.edu/pub/RFdiffusion/76d00716416567174cdb7ca96e208296/InpaintSeq_Fold_ckpt.pt",
    "ActiveSite_ckpt.pt": "http://files.ipd.uw.edu/pub/RFdiffusion/5532d2e1f3a4738decd58b19d633b3c3/ActiveSite_ckpt.pt",
    "Base_epoch8_ckpt.pt": "http://files.ipd.uw.edu/pub/RFdiffusion/12fc204edeae5b57713c5ad7dcb97d39/Base_epoch8_ckpt.pt",
}


# -------------------------
# Image definition
# -------------------------
# NOTE:
# A newer, modern CUDA/PyTorch-style environment 
# (https://github.com/JMB-Scripts/RFdiffusion-dockerfile-nvidia-RTX5090/blob/main/RTX-5090.dockerfile) 

runtime_image = (
    Image.micromamba(python_version="3.10")
    .apt_install(
        "git",
        "wget",
        "curl",
        "build-essential",
        "ca-certificates",
        "zstd",
        "tar",
        "fd-find",  # prefer fd over find
    )
    .run_commands(
        # CHANGED: ensure the 'fd' binary is available (Ubuntu often exposes it as 'fdfind').
        "bash -lc 'command -v fd >/dev/null 2>&1 || (command -v fdfind >/dev/null 2>&1 && ln -sf $(command -v fdfind) /usr/local/bin/fd) || true'"
    )
    .run_commands(
       f"git clone --depth 1 https://github.com/RosettaCommons/RFdiffusion.git {RFD_REPO_DIR}"
    )
    .env(
        {
            "PYTHONPATH": RFD_REPO_DIR,
            "PYTHONUNBUFFERED": "1",
        }
    )
    .run_commands(
        # install CUDA-enabled PyTorch from official index (avoid accidental CPU-only wheels).
        # Pin torch < 2.6 to avoid the torch.load(weights_only=...) default behavior change.
        "python -m pip install --no-cache-dir -U pip && "
        "python -m pip install --no-cache-dir "
        "--index-url https://download.pytorch.org/whl/cu121 "
        "torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1"
    )
    .uv_pip_install(
        "numpy",
        "scipy",
        "tqdm",
        "pyyaml",
        "omegaconf",
        "hydra-core",
        "biopython",
        "pandas",
        "einops",
        "opt_einsum",
        "dm-tree",
        "pyrsistent",   # RFdiffusion symmetry 
        "aiohttp",  # async checkpoint download
        "torchdata>=0.7",  # DGL / datapipes support
    )
    .run_commands(
    # build/install NVIDIA SE3Transformer in one chained step.
       f"cd {RFD_REPO_DIR}/env/SE3Transformer && "
        "python -m pip install --no-cache-dir -r requirements.txt && "
        "python setup.py install"
    )
    .run_commands(
        # ensure DGL CUDA wheel. Uninstall any CPU build first.
        "python -m pip uninstall -y dgl || true && "
        'python -m pip install --no-cache-dir "dgl==1.1.3" -f https://data.dgl.ai/wheels/cu121/repo.html'
    )


app = App(APP_NAME, image=runtime_image)


# -------------------------
# Helpers
# -------------------------
def run_command(
    cmd: list[str],
    cwd: str | None = None,
    env: dict[str, str] | None = None,
) -> None:
    """Run a command and stream stdout/stderr."""
    import subprocess as sp

    print("Running:", " ".join(cmd))
    with sp.Popen(
        cmd,
        cwd=cwd,
        env=env,
        stdout=sp.PIPE,
        stderr=sp.STDOUT,
        bufsize=1,
        encoding="utf-8",
    ) as p:
        assert p.stdout is not None
        for line in p.stdout:
            print(line, end="")
        rc = p.wait()
        if rc != 0:
            raise sp.CalledProcessError(rc, cmd)

def build_runtime_env() -> dict[str, str]:
    """
     Build a consistent runtime environment.
    - Keep the env dict explicit so subprocesses inherit expected settings.
    """
    env = dict(os.environ)
    env["PYTHONPATH"] = RFD_REPO_DIR
    # (Optional) quiet DGL backend warning
    env.setdefault("DGLBACKEND", "pytorch")
    return env

def package_dir_to_tar_zst(dir_path: str) -> bytes:
    """Package a directory into tar.zst and return bytes."""
    import subprocess as sp

    dp = Path(dir_path)
    parent = str(dp.parent)
    name = dp.name
    cmd = ["tar", "--zstd", "-cf", "-", name]
    return sp.check_output(cmd, cwd=parent)

def collect_outputs_for_bundle(root_dir: str) -> list[Path]:
    """
    Collect the subset of output files that are typically useful to download.
    This avoids bundling unnecessary large intermediate files.
    """
    import subprocess as sp
    root = Path(root_dir)
    # Prefer fd (multi-threaded); fallback to find.
    has_fd = sp.run(["bash", "-lc", "command -v fd >/dev/null 2>&1"]).returncode == 0

    if has_fd:
        cmd = (
            f"cd {root} && "
            r"fd -t f '\.(pdb|trb|json|yaml|yml|log|txt|csv)$' ."
        )
    else:
        cmd = (
            f"cd {root} && "
            r"find . -type f \( "
            r"-name '*.pdb' -o -name '*.trb' -o -name '*.json' -o "
            r"-name '*.yaml' -o -name '*.yml' -o -name '*.log' -o "
            r"-name '*.txt' -o -name '*.csv' "
            r"\)"
        )

    out = sp.check_output(["bash", "-lc", cmd], text=True).strip().splitlines()
    files = [root / p.lstrip("./") for p in out if p.strip()]
    return files

def package_files_to_tar_zst(files: list[Path], base_dir: str) -> bytes:
    """Create a tar.zst containing only selected files, preserving relative paths."""
    import subprocess as sp
    import tempfile

    base = Path(base_dir)

    with tempfile.NamedTemporaryFile(mode="w", delete=False) as f:
        for p in files:
            rel = p.relative_to(base)
            f.write(str(rel) + "\n")
        filelist = f.name

    cmd = ["bash", "-lc", f"tar --zstd -cf - -C {base} -T {filelist}"]
    return sp.check_output(cmd)


# -------------------------
# Step 1: download model weights into the models Volume
# -------------------------
async def _download_file(session, url: str, local_path: Path) -> None:
    """Download a file asynchronously via aiohttp streaming."""
    async with session.get(url) as response:
        response.raise_for_status()
        local_path.parent.mkdir(parents=True, exist_ok=True)
        with open(local_path, "wb") as f:
            while True:
                chunk = await response.content.read(8192)
                if not chunk:
                    break
                f.write(chunk)

@app.function(
    timeout=TIMEOUT * 2,
    volumes={RFD_MODELS_DIR: RFD_VOLUME},
)
async def download_rfdiffusion_models(force: bool = False) -> None:
    """
    Download RFdiffusion checkpoints into the persistent models Volume.

    URLs are copied verbatim from:
    https://github.com/RosettaCommons/RFdiffusion/blob/main/scripts/download_models.sh
    """
    import asyncio
    import aiohttp

    headers = {"User-Agent": "Mozilla/5.0"}
    model_dir = Path(RFD_MODELS_DIR)

    async with aiohttp.ClientSession(headers=headers) as session:
        tasks = []
        for fname, url in RFD_CHECKPOINT_URLS.items():
            dst = model_dir / fname
            if force or not dst.exists():
                print(f"downloading {fname} -> {dst}")
                tasks.append(_download_file(session, url, dst))

        if tasks:
            await asyncio.gather(*tasks)
        else:
            print("All RFdiffusion checkpoints already present; nothing to download.")

    # Commit so checkpoints are visible immediately for remote inference jobs.
    RFD_VOLUME.commit()
    print("RFdiffusion checkpoints downloaded and committed.")


# -------------------------
# Step 2: inference function (remote GPU job)
# -------------------------
@app.function(
    gpu=GPU,
    cpu=(2, 4),
    memory=(4096, 65536),
    timeout=TIMEOUT,
    image=runtime_image,
    volumes={
      RFD_MODELS_DIR: RFD_VOLUME.read_only(),
      # output cache volume.
      RFD_OUT_DIR: RFD_OUT_VOLUME,
    },
)
def rfdiffusion_infer(
    input_pdb_bytes: bytes,
    input_pdb_name: str,
    run_name: str,
    rfd_args: str,
) -> bytes:
    """
    Run RFdiffusion inference inside the container and return a .tar.zst bundle.

    - Outputs are cached under /root/rfdiffusion_outputs/<run_name> on a persistent Volume.
    - The returned archive contains the most useful artifacts (PDB/TRB/log/JSON/YAML by default).
    """
    from tempfile import TemporaryDirectory

    env = build_runtime_env()  # ### CHANGED
    rfd_debug = os.environ.get("RFD_DEBUG", "0") == "1"
  
    with TemporaryDirectory() as tmpdir:
        tmp = Path(tmpdir)

        input_pdb = tmp / input_pdb_name
        input_pdb.write_bytes(input_pdb_bytes)

        out_dir = tmp / f"{run_name}_outputs"
        out_dir.mkdir(parents=True, exist_ok=True)

        # =====================================================
        # ✅ Runtime GPU / DGL CUDA sanity check (runs inside GPU job)
        # =====================================================
        run_command(
            [
                "bash",
                "-lc",
                "python -c \""
                "import torch, dgl; "
                "print('torch', torch.__version__); "
                "print('torch cuda', torch.cuda.is_available()); "
                "print('device', torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'none'); "
                "print('dgl', dgl.__version__); "
                "import sys; "
                "sys.exit(0) if torch.cuda.is_available() else sys.exit(2)\"",
            ],
            env=env,
        )

        # Only test DGL->CUDA if CUDA is available
        run_command(
            [
                "bash",
                "-lc",
                "python -c \""
                "import torch, dgl; "
                "assert torch.cuda.is_available(); "
                "g=dgl.graph(([0],[1])); "
                "g=g.to('cuda'); "
                "print('dgl graph device', g.device)\"",
            ],
            env=env,
        )

        run_infer_py = f"{RFD_REPO_DIR}/scripts/run_inference.py"

        # ### CHANGED (关键): 用 shlex.split 正确切分参数，避免空格/[] 引号问题
        # 例如：contigmap.contigs=[10-50/0 E333-526] 这种带空格的 token，
        # 以前在 bash 里很容易被拆开导致报错；现在不会。
        extra_tokens = shlex.split(rfd_args) if rfd_args else []

        # =====================================================
        # ✅ Check model weights in Volume and copy to repo default path
        # =====================================================
        default_models_dir = f"{RFD_REPO_DIR}/models"
        ckpt_src = f"{RFD_MODELS_DIR}/Complex_base_ckpt.pt"      # Volume mount
        ckpt_dst = f"{default_models_dir}/Complex_base_ckpt.pt"  # RFdiffusion default

        # 1) list what we have in the mounted Volume
        run_command(
            ["bash", "-lc", f"echo '=== MODELS VOLUME ({RFD_MODELS_DIR}) ==='; ls -lah {RFD_MODELS_DIR}"],
            env=env,
        )

        # 2) fail fast if checkpoint missing
        run_command(
            ["bash", "-lc", f"test -f {ckpt_src} && ls -lh {ckpt_src} || (echo 'MISSING ckpt: {ckpt_src}'; exit 1)"],
            env=env,
        )

        # 3) copy into repo default models dir (what RFdiffusion actually uses)
        run_command(["bash", "-lc", f"mkdir -p {default_models_dir}"], env=env)
        run_command(
            ["bash", "-lc", f"cp -f {ckpt_src} {ckpt_dst} && echo '=== COPIED CKPT ===' && ls -lh {ckpt_dst}"],
            env=env,
        )

        # ===============================
        # 正式运行 RFdiffusion
        # ===============================

        # ### CHANGED: 直接用 subprocess 列表参数调用 python（不再用 bash -lc 拼字符串）
        cmd = [
            "python",
            run_infer_py,
            f"inference.input_pdb={input_pdb}",
            f"inference.output_prefix={out_dir}/rfout",
            *extra_tokens,
        ]

        # 在 repo 目录下运行（让相对路径/配置更稳定）
        run_command(cmd, cwd=RFD_REPO_DIR, env=env)

        # optional: list outputs
        run_command(
            ["bash", "-lc", f'echo "=== outputs ==="; find "{out_dir}" -maxdepth 3 -type f | head -n 200'],
            env=env,
        )

        tar_bytes = package_dir_to_tar_zst(str(out_dir))
        return tar_bytes


# -------------------------
# Local entrypoint (CLI)
# -------------------------
@app.local_entrypoint()
def main(
    run_name: str | None = None,
    input_pdb: str | None = None,
    rfd_args: str = "",
    download_models: bool = False,
    force_redownload: bool = False,
    out_dir: str | None = None,
):
    if download_models:
        download_rfdiffusion_models.remote(force=force_redownload)
        return

    if run_name is None:
        raise ValueError("Missing required --run-name")
    if input_pdb is None:
        raise ValueError("Missing required --input-pdb (path to local .pdb)")

    input_path = Path(input_pdb)
    if not input_path.exists():
        raise FileNotFoundError(f"Input PDB not found: {input_pdb}")

    pdb_bytes = input_path.read_bytes()

    local_out = Path(out_dir).expanduser().resolve() if out_dir else Path.cwd()
    local_out.mkdir(parents=True, exist_ok=True)
    out_file = local_out / f"{run_name}_rfdiffusion_outputs.tar.zst"
    if out_file.exists():
        raise FileExistsError(f"Output already exists: {out_file}")

    tar_bytes = rfdiffusion_infer.remote(
        input_pdb_bytes=pdb_bytes,
        input_pdb_name=input_path.name,
        run_name=run_name,
        rfd_args=rfd_args,
    )
    out_file.write_bytes(tar_bytes)
    print(f"Done. Saved: {out_file}")
